{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-01T10:15:52.809635Z",
     "iopub.status.busy": "2025-08-01T10:15:52.808911Z",
     "iopub.status.idle": "2025-08-01T10:15:53.198837Z",
     "shell.execute_reply": "2025-08-01T10:15:53.198015Z",
     "shell.execute_reply.started": "2025-08-01T10:15:52.809605Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/gate-dsai-llm/build_index.ipynb\n",
      "/kaggle/input/gate-dsai-llm/GATE2024_DA_Sample_Paper.pdf\n",
      "/kaggle/input/gate-dsai-llm/README.md\n",
      "/kaggle/input/gate-dsai-llm/Chat_bot.ipynb\n",
      "/kaggle/input/gate-dsai-llm/GATE_DA_2025_Question_Paper.pdf\n",
      "/kaggle/input/gate-dsai-llm/GATE_DA_2025_Syllabus.pdf\n",
      "/kaggle/input/gate-dsai-llm/Machine-Learning/ML-A-Probabilistic-Perspective-Murphy.pdf\n",
      "/kaggle/input/gate-dsai-llm/Machine-Learning/UPenn-CIS520-Midterm2019-Solutions.pdf\n",
      "/kaggle/input/gate-dsai-llm/Machine-Learning/CMU-ML-Notes.pdf\n",
      "/kaggle/input/gate-dsai-llm/Machine-Learning/CS229-Stanford-Lecture-Notes-Repo-Copy.pdf\n",
      "/kaggle/input/gate-dsai-llm/Machine-Learning/ML_super_cheatsheet.pdf\n",
      "/kaggle/input/gate-dsai-llm/Machine-Learning/UPenn-CIS520-Final2017-Solutions.pdf\n",
      "/kaggle/input/gate-dsai-llm/Machine-Learning/UPenn-CIS520-Final2018-Solutions.pdf\n",
      "/kaggle/input/gate-dsai-llm/Machine-Learning/UPenn-CIS520-Midterm2022-Solutions.pdf\n",
      "/kaggle/input/gate-dsai-llm/Machine-Learning/UPenn-CIS520-Midterm2018-Solutions.pdf\n",
      "/kaggle/input/gate-dsai-llm/Machine-Learning/CS229-Stanford-Lecture-Notes.pdf\n",
      "/kaggle/input/gate-dsai-llm/Machine-Learning/Learning-From-Data-Abu-Mostafa.pdf\n",
      "/kaggle/input/gate-dsai-llm/Machine-Learning/UPenn-CIS520-Final2019-Solutions.pdf\n",
      "/kaggle/input/gate-dsai-llm/Artificial-Intelligence/AI_All_cheat_sheet.pdf\n",
      "/kaggle/input/gate-dsai-llm/Artificial-Intelligence/handout3.pdf\n",
      "/kaggle/input/gate-dsai-llm/Artificial-Intelligence/handout2.pdf\n",
      "/kaggle/input/gate-dsai-llm/Artificial-Intelligence/handout4.pdf\n",
      "/kaggle/input/gate-dsai-llm/Artificial-Intelligence/handout1.pdf\n",
      "/kaggle/input/gate-dsai-llm/Probability-Statistics/Probability-Review-IIT-D.pdf\n",
      "/kaggle/input/gate-dsai-llm/Probability-Statistics/Intro-to-Probability-Blitzstein-Hwang.pdf\n",
      "/kaggle/input/gate-dsai-llm/Probability-Statistics/probability_cheatsheet.pdf\n",
      "/kaggle/input/gate-dsai-llm/Probability-Statistics/All-of-Statistics-Wasserman.pdf\n",
      "/kaggle/input/gate-dsai-llm/Probability-Statistics/Intro-to-Probability-Pishro-Nik.pdf\n",
      "/kaggle/input/gate-dsai-llm/Probability-Statistics/Multivariate-Gaussians-Review-IIT-D.pdf\n",
      "/kaggle/input/gate-dsai-llm/Probability-Statistics/A-First-Course-in-Probability-Sheldon-Ross.pdf\n",
      "/kaggle/input/gate-dsai-llm/Database-Management/Fundamentals-of-Database-Systems-Elmasri-Navathe.pdf\n",
      "/kaggle/input/gate-dsai-llm/Database-Management/Intro-to-Data-Mining-Tan.pdf\n",
      "/kaggle/input/gate-dsai-llm/Database-Management/Indexing-File-Organization-GWU.pdf\n",
      "/kaggle/input/gate-dsai-llm/Database-Management/Data-Mining-Concepts-and-Techniques-Han.pdf\n",
      "/kaggle/input/gate-dsai-llm/my_vector_index/index.faiss\n",
      "/kaggle/input/gate-dsai-llm/my_vector_index/index.pkl\n",
      "/kaggle/input/gate-dsai-llm/Programming-and-Algorithms/Python-Programming-Berkeley.pdf\n",
      "/kaggle/input/gate-dsai-llm/Programming-and-Algorithms/Data-Structures-Algorithms-in-Python-Sample.pdf\n",
      "/kaggle/input/gate-dsai-llm/Programming-and-Algorithms/Data-Structures-and-Algorithms-Princeton.pdf\n",
      "/kaggle/input/gate-dsai-llm/Programming-and-Algorithms/DS-Algo-Cheatsheet-WMich.pdf\n",
      "/kaggle/input/gate-dsai-llm/Programming-and-Algorithms/Algorithms-Notes-UWA.pdf\n",
      "/kaggle/input/gate-dsai-llm/Programming-and-Algorithms/Algorithm-Design-Kleinberg-Tardos.pdf\n",
      "/kaggle/input/gate-dsai-llm/Programming-and-Algorithms/Big-O-Refresher-MIT.pdf\n",
      "/kaggle/input/gate-dsai-llm/Programming-and-Algorithms/Data-Structures-Stanford.pdf\n",
      "/kaggle/input/gate-dsai-llm/Linear-Algebra/Linear-Algebra-Review-for-ML-IIT-D.pdf\n",
      "/kaggle/input/gate-dsai-llm/Linear-Algebra/MIT18_06S10ZoomNotes-Gilbert-Strang.pdf\n",
      "/kaggle/input/gate-dsai-llm/Linear-Algebra/Linear-Algebra-Done-Right-Sheldon-Axler.pdf\n",
      "/kaggle/input/gate-dsai-llm/Linear-Algebra/refresher-algebra-calculus.pdf\n",
      "/kaggle/input/gate-dsai-llm/Calculus-and-Optimization/Convex-Optimization-Boyd.pdf\n",
      "/kaggle/input/gate-dsai-llm/Calculus-and-Optimization/Calculus-Online-Textbook-Gilbert-Strang.pdf\n",
      "/kaggle/input/gate-dsai-llm/Calculus-and-Optimization/NPTEL-Math-for-ML-Assignment-Week5.pdf\n",
      "/kaggle/input/gate-dsai-llm/Calculus-and-Optimization/Optimization-Notes-IIT-D.pdf\n",
      "/kaggle/input/gate-dsai-llm/Calculus-and-Optimization/calculus_cheat_sheet_all.pdf\n"
     ]
    }
   ],
   "source": [
    " # This Python 3 environment comes with many helpful analytics libraries installed\n",
    " # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    " # For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " =============================================================================\n",
    " STEP 1: ENVIRONMENT SETUP AND LIBRARY INSTALLATION\n",
    " =============================================================================\n",
    "\n",
    " In this step, we install all the necessary Python packages. Kaggle environments\n",
    " are ephemeral, so these installations are required for each session. We use\n",
    " quiet flags (-q) to keep the output clean.\n",
    "\n",
    " Key Libraries:\n",
    " - langchain: The core framework for building LLM applications.\n",
    " - transformers: Provides access to Hugging Face models and pipelines.\n",
    " - faiss-cpu: A library for efficient similarity search (our vector store).\n",
    " - sentence-transformers: Used for generating high-quality text embeddings.\n",
    " - pypdf: A robust library for extracting text from PDF documents.\n",
    " - accelerate: Required for efficiently loading and running large models on GPUs.\n",
    "\n",
    " ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T10:16:20.322032Z",
     "iopub.status.busy": "2025-08-01T10:16:20.321598Z",
     "iopub.status.idle": "2025-08-01T10:18:06.134474Z",
     "shell.execute_reply": "2025-08-01T10:18:06.133058Z",
     "shell.execute_reply.started": "2025-08-01T10:16:20.322007Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: Installing required libraries...\n",
      "\u001b[33mWARNING: langchain-community 0.3.27 does not provide the extra 'pdf'\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "pandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\n",
      "dataproc-spark-connect 0.7.5 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\n",
      "bigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\n",
      "bigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m102.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hLibrary installation complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"STEP 1: Installing required libraries...\")\n",
    "!pip install -q langchain \"langchain-community[pdf]\"\n",
    "!pip install -q faiss-cpu InstructorEmbedding\n",
    "!pip install -q transformers torch accelerate\n",
    "print(\"Library installation completed.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " =============================================================================\n",
    " STEP 2: DATA LOADING AND DOCUMENT PROCESSING\n",
    " =============================================================================\n",
    "\n",
    " Here, we define the path to our custom dataset on Kaggle. We then\n",
    " recursively walk through the directory, identify all PDF files, and use\n",
    " LangChain's PyPDFLoader to load and split the documents into manageable\n",
    " chunks. This chunking is essential for the retrieval process.\n",
    "\n",
    " ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T10:19:28.467241Z",
     "iopub.status.busy": "2025-08-01T10:19:28.466826Z",
     "iopub.status.idle": "2025-08-01T10:28:37.618632Z",
     "shell.execute_reply": "2025-08-01T10:28:37.617542Z",
     "shell.execute_reply.started": "2025-08-01T10:19:28.467203Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 2: Loading documents from '/kaggle/input/gate-dsai-llm'...\n",
      "  -> Successfully loaded and split: GATE2024_DA_Sample_Paper.pdf\n",
      "  -> Successfully loaded and split: GATE_DA_2025_Question_Paper.pdf\n",
      "  -> Successfully loaded and split: GATE_DA_2025_Syllabus.pdf\n",
      "  -> Successfully loaded and split: ML-A-Probabilistic-Perspective-Murphy.pdf\n",
      "  -> Successfully loaded and split: UPenn-CIS520-Midterm2019-Solutions.pdf\n",
      "  -> Successfully loaded and split: CMU-ML-Notes.pdf\n",
      "  -> Successfully loaded and split: CS229-Stanford-Lecture-Notes-Repo-Copy.pdf\n",
      "  -> Successfully loaded and split: ML_super_cheatsheet.pdf\n",
      "  -> Successfully loaded and split: UPenn-CIS520-Final2017-Solutions.pdf\n",
      "  -> Successfully loaded and split: UPenn-CIS520-Final2018-Solutions.pdf\n",
      "  -> Successfully loaded and split: UPenn-CIS520-Midterm2022-Solutions.pdf\n",
      "  -> Successfully loaded and split: UPenn-CIS520-Midterm2018-Solutions.pdf\n",
      "  -> Successfully loaded and split: CS229-Stanford-Lecture-Notes.pdf\n",
      "  -> Successfully loaded and split: Learning-From-Data-Abu-Mostafa.pdf\n",
      "  -> Successfully loaded and split: UPenn-CIS520-Final2019-Solutions.pdf\n",
      "  -> Successfully loaded and split: AI_All_cheat_sheet.pdf\n",
      "  -> Successfully loaded and split: handout3.pdf\n",
      "  -> Successfully loaded and split: handout2.pdf\n",
      "  -> Successfully loaded and split: handout4.pdf\n",
      "  -> Successfully loaded and split: handout1.pdf\n",
      "  -> Successfully loaded and split: Probability-Review-IIT-D.pdf\n",
      "  -> Successfully loaded and split: Intro-to-Probability-Blitzstein-Hwang.pdf\n",
      "  -> Successfully loaded and split: probability_cheatsheet.pdf\n",
      "  -> Successfully loaded and split: All-of-Statistics-Wasserman.pdf\n",
      "  -> Successfully loaded and split: Intro-to-Probability-Pishro-Nik.pdf\n",
      "  -> Successfully loaded and split: Multivariate-Gaussians-Review-IIT-D.pdf\n",
      "  -> Successfully loaded and split: A-First-Course-in-Probability-Sheldon-Ross.pdf\n",
      "  -> Successfully loaded and split: Fundamentals-of-Database-Systems-Elmasri-Navathe.pdf\n",
      "  -> Successfully loaded and split: Intro-to-Data-Mining-Tan.pdf\n",
      "  -> Successfully loaded and split: Indexing-File-Organization-GWU.pdf\n",
      "  -> Successfully loaded and split: Data-Mining-Concepts-and-Techniques-Han.pdf\n",
      "  -> Successfully loaded and split: Python-Programming-Berkeley.pdf\n",
      "  -> Successfully loaded and split: Data-Structures-Algorithms-in-Python-Sample.pdf\n",
      "  -> Successfully loaded and split: Data-Structures-and-Algorithms-Princeton.pdf\n",
      "  -> Successfully loaded and split: DS-Algo-Cheatsheet-WMich.pdf\n",
      "  -> Successfully loaded and split: Algorithms-Notes-UWA.pdf\n",
      "  -> Successfully loaded and split: Algorithm-Design-Kleinberg-Tardos.pdf\n",
      "  -> Successfully loaded and split: Big-O-Refresher-MIT.pdf\n",
      "  -> Successfully loaded and split: Data-Structures-Stanford.pdf\n",
      "  -> Successfully loaded and split: Linear-Algebra-Review-for-ML-IIT-D.pdf\n",
      "  -> Successfully loaded and split: MIT18_06S10ZoomNotes-Gilbert-Strang.pdf\n",
      "  -> Successfully loaded and split: Linear-Algebra-Done-Right-Sheldon-Axler.pdf\n",
      "  -> Successfully loaded and split: refresher-algebra-calculus.pdf\n",
      "  -> Successfully loaded and split: Convex-Optimization-Boyd.pdf\n",
      "  -> Successfully loaded and split: Calculus-Online-Textbook-Gilbert-Strang.pdf\n",
      "  -> Successfully loaded and split: NPTEL-Math-for-ML-Assignment-Week5.pdf\n",
      "  -> Successfully loaded and split: Optimization-Notes-IIT-D.pdf\n",
      "  -> Successfully loaded and split: calculus_cheat_sheet_all.pdf\n",
      "\n",
      "Total document chunks loaded: 11473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "docs_path = \"/kaggle/input/gate-dsai-llm\"\n",
    "\n",
    "print(f\"STEP 2: Loading documents from '{docs_path}'...\")\n",
    "\n",
    "all_docs = []\n",
    "# os.walk is a Python generator that explores a directory tree.\n",
    "for root, _, files in os.walk(docs_path):\n",
    "    for file in files:\n",
    "        if file.endswith(\".pdf\"):\n",
    "            try:\n",
    "                file_path = os.path.join(root, file)\n",
    "                loader = PyPDFLoader(file_path)\n",
    "                # load_and_split() is more efficient than loading then splitting.\n",
    "                loaded_docs = loader.load_and_split()\n",
    "                all_docs.extend(loaded_docs)\n",
    "                print(f\"  -> Successfully loaded and split: {file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  -> ERROR loading {file}: {e}\")\n",
    "\n",
    "if not all_docs:\n",
    "    raise ValueError(\"No documents were loaded. Check the dataset path and ensure it contains PDF files.\")\n",
    "\n",
    "print(f\"\\nTotal document chunks loaded: {len(all_docs)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " =============================================================================\n",
    " STEP 3: VECTOR EMBEDDING AND INDEX CREATION\n",
    " =============================================================================\n",
    "\n",
    " This is the core of the \"Retrieval\" part of RAG. We convert our text chunks\n",
    " into numerical vectors (embeddings) using a sentence-transformer model.\n",
    " These vectors are then stored in a FAISS index, which allows for extremely\n",
    " fast similarity searches. When a user asks a question, we will embed their\n",
    " question and use this index to find the most semantically relevant chunks.\n",
    "\n",
    " ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T10:37:23.721495Z",
     "iopub.status.busy": "2025-08-01T10:37:23.720767Z",
     "iopub.status.idle": "2025-08-01T10:49:06.074335Z",
     "shell.execute_reply": "2025-08-01T10:49:06.073402Z",
     "shell.execute_reply.started": "2025-08-01T10:37:23.721466Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 3: Creating vector embeddings and FAISS index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36/3473037497.py:9: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
      "2025-08-01 10:37:42.650595: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754044663.008009      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754044663.096525      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90c71931917a4fbfbb5eaa00ca91faf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "595f401ed0c34b75a6fa6c9df5797a88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f07f485e17c4bb7a753717dedc715fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "834c593b3bd74615b34e0eb8dc11d397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ba99112f9c64f4e9b805b128a190b1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeabe5ed9c7d4c43a6667d68186bf682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9080164a2fe146a4ac36f2a80c1cb4ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a432be455fa3411db53862f3416829f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f92ae31526c3476fbac8564555e16dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82406b2392424b2f934b11a9072ee310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c68fc2488ada4fef9d0f67b275e8291a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector index created successfully.\n",
      "\n",
      "STEP 4: Index successfully saved to '/kaggle/working/my_vector_index'\n",
      "\n",
      "--- BUILD PROCESS COMPLETE ---\n",
      "You can now run the 'chatbot.ipynb' notebook.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "print(\"STEP 3: Creating vector embeddings and FAISS index...\")\n",
    "\n",
    "# Initialize the embedding model. 'all-MiniLM-L6-v2' is a great, lightweight\n",
    "# model that provides excellent performance for semantic search.\n",
    "embedding_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "\n",
    "# Create the FAISS vector store from our document chunks and embeddings.\n",
    "# This process can take a few minutes depending on the number of documents.\n",
    "vector_store = FAISS.from_documents(all_docs, embeddings)\n",
    "\n",
    "print(\"Vector index created successfully.\\n\")\n",
    "output_path = \"/kaggle/input/gate-dsai-llm/my_vector_index\"\n",
    "vector_store.save_local(output_path)\n",
    "\n",
    "print(f\"STEP 4: Index successfully saved to '{output_path}'\")\n",
    "print(\"\\n--- BUILD PROCESS COMPLETE ---\")\n",
    "print(\"You can now run the 'chatbot.ipynb' notebook.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7987370,
     "sourceId": 12639824,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
